{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from fastavro import json_writer, parse_schema, writer\n",
    "import json\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "### -----------------------------------------------------------\n",
    "http_log = []\n",
    "fields = ['timestamp', 'http_method', 'http_path', 'user_id']\n",
    "\n",
    "fname = 'SOME STRING'\n",
    "foutput = 'SOME STRING'\n",
    "with open(fname) as data :\n",
    "    for line in data :\n",
    "        temp_http = {\n",
    "            fields[0]: line.strip().split()[0],\n",
    "            fields[1]: line.strip().split()[1],\n",
    "            fields[2]: line.strip().split()[2],\n",
    "            fields[3]: line.strip().split()[3]\n",
    "        }\n",
    "        http_log.append(temp_http)\n",
    "\n",
    "\n",
    "with open(foutput, 'wr') as out_file:\n",
    "    json.dump(http_log, out_file, indent = 4)\n",
    "    out_file.close()\n",
    "\n",
    "### -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the file is converted to JSON we will convert it to AVRO\n",
    "### -----------------------------------------------------------\n",
    "key = \"FILE.json\"\n",
    "schemaFileName = \"http_log.avsc\"\n",
    "with open(r'DIRECTORY' + schemaFileName) as sc:\n",
    "    w = json.load(sc)\n",
    "schema = parse_schema(w)\n",
    "with open(r'DIRECTORY' + key) as js:\n",
    "    x=json.load(js)\n",
    "with open('C:/Path/to/file/output.avro', 'wb') as out:\n",
    "    writer(out, schema,x, codec='deflate')\n",
    "### -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the files into a S3 Server\n",
    "### -----------------------------------------------------------\n",
    "ACCESS_KEY = 'SomeString'\n",
    "SECRET_KEY = 'SomeString'\n",
    "\n",
    "def uploadAWS (local_file, bucket, s3_file) :\n",
    "    s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY,\n",
    "                      aws_secret_access_key=SECRET_KEY)\n",
    "    try :\n",
    "        s3.upload_file (local_file, bucket, s3_file)\n",
    "        print(\"Upload Success\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"File was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError :\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "# Uploading remaining files to S3\n",
    "uploaded = uploadAWS('http_log.avsc', 'perxassessment', 'http_log.avsc')\n",
    "uploaded = uploadAWS('http_log.avro', 'perxassessment', 'http_log.txt')\n",
    "uploaded = uploadAWS('campaign_reward_mapping.csv', 'perxassessment', 'campaign_reward_mapping.csv')\n",
    "### -----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Psycopg2 to enable SQL functions within RedShift\n",
    "### -----------------------------------------------------------\n",
    "conn = psycopg2.connect(\n",
    "    host = 'Some String',\n",
    "    user = 'Some String',\n",
    "    port = 'Some String',\n",
    "    password = 'Some String',\n",
    "    dbname = 'perxassessment'\n",
    ")\n",
    "cur = conn.connect()\n",
    "\n",
    "# Create initial campaign reward mapping table\n",
    "cur.execute('''\n",
    "CREATE TABLE campaign_reward_mapping (\n",
    "campaign_id int\n",
    "  CONSTRAINT fk_campaign\n",
    "  \tFOREIGN KEY(campaign_id)\n",
    "  \t  REFERENCES campaign(id),\n",
    "reward_id int\n",
    "  CONSTRAINT fk_reward\n",
    "    FOREIGN KEY (reward_id)\n",
    "      REFERENCES reward_campaign(id)\n",
    ")\n",
    "''')\n",
    "\n",
    "\n",
    "# Create Table for http_log\n",
    "cur.execute('''\n",
    "CREATE TABLE http_log (\n",
    "timestamp DATETIME, http_method string, http_path string, user_id int\n",
    ")\n",
    "''')\n",
    "\n",
    "# I've included region recognizing that Redshifts and S3 servers could be in different locations\n",
    "# COPY http_log AVRO file into the RedShift table\n",
    "cur.execute('''\n",
    "COPY http_log\n",
    "FROM 's3://perxassessment/http_log.avro'\n",
    "iam_role 'ROLE'\n",
    "format as avro 'auto'\n",
    "region 'REGION'\n",
    "''')\n",
    "\n",
    "# COPY campaign_reward_mapping CSV file into its RedShif table\n",
    "cur.execute('''\n",
    "COPY campaign_reward_mapping\n",
    "FROM 's3://perxassessment/campaign_reward_mapping.csv'\n",
    "iam_role 'ROLE'\n",
    "format as csv 'auto'\n",
    "region 'REGION'\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Construct Output Query\n",
    "# Notes/Commentary:\n",
    "# - Use CTE to hold data in temp view and perform some level of data cleanup w/ Regex\n",
    "#   <http_path> required some level of cleansing\n",
    "# - Self-Join table\n",
    "# - There are instances of Users viewing the campaign but claiming no rewards\n",
    "#   Using a left join we can identify instances where there were entries into a campaign\n",
    "#   and there were no rewards. Additionally, we can define a booleans for instances where a campaign\n",
    "#   has a reward but the user never claimed it. \n",
    "cur.execute('''\n",
    "WITH CTE AS (\n",
    "  SELECT \n",
    "    timestamp,\n",
    "    substring(http_path from '\\d.*') AS Campaign_id,\n",
    "    user_id\n",
    "  FROM \n",
    "    http_logs\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  user_id,\n",
    "  min(timestamp) AS session_start,\n",
    "  (CASE WHEN max(timestamp) = min(timestamp) THEN NULL ELSE max(timestamp)) AS session_end,\n",
    "  L.campaign_id AS campaigns,\n",
    "  R.reward_id AS rewards_issued,\n",
    "  (CASE WHEN (L.campaign_id IS NOT NULL AND R.reward_id IS NULL) THEN 'False' ELSE CASE WHEN (min(timestamp) = max(timestamp), 'False','True')) AS reward_driven_by_campaign_view\n",
    "FROM CTE L\n",
    "LEFT JOIN campaign_reward_mapping R\n",
    "  ON L.Campaign_id = R.campaign_id\n",
    "\n",
    "GROUP BY user_id, L.campaign_id, R.reward_id\n",
    "\n",
    "ORDER BY user_id, L.campaign_id, R.reward_id\n",
    "''')\n",
    "\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
